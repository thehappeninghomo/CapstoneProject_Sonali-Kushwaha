{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the libraries and load the MNIST dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Traning samples: 60000       |              Testing samples: 10000 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importing the necessary modules\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D \r\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout \r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Importing the MNIST dataset from keras library\r\n",
    "data = tf.keras.datasets.mnist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Splitting the MNIST dataset into training and testing sets\r\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Checking the values of each pixel of any random index before normalising the training set\r\n",
    "print(x_train[128])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  73 253 253  63\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 115 252 252 144\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 217 252 252 144\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  63 237 252 252 144\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 252 252   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 252 252   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 252 252   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 191 252 252 252   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 145 255 253 253 253   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  32 237 253 252 252 210   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  37 252 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  37 252 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  21 207 255 253 253 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  27 221 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  16 190 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 145 255 253 253 253   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252 252 210   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  62 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Checking maximum value of the channel to know if images are in gray level\r\n",
    "x_train.max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Normalizing \r\n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\r\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Checking the values of each pixel after normalizing the sets\r\n",
    "print(x_test[128])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0334356  0.13178944 0.12538645\n",
      "  0.13720214 0.23752672 0.320807   0.29975335 0.27031627 0.26712058\n",
      "  0.30992802 0.46001141 0.52173312 0.40191448 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3068664  0.42994117 0.31120827 0.27447056 0.26113541\n",
      "  0.28574331 0.31503544 0.31829087 0.29856856 0.26924783 0.26606477\n",
      "  0.30870301 0.45819318 0.56671011 0.84950107 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.79887077 0.57653687 0.45143823 0.32406811 0.27447056 0.26113541\n",
      "  0.28574331 0.31503544 0.2000326  0.18719775 0.20620964 0.26606477\n",
      "  0.30870301 0.45819318 0.48575153 0.0913442  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6015027  0.55793891 0.45143823 0.32406811 0.19169372 0.04041381\n",
      "  0.04422218 0.04875549 0.         0.         0.01602666 0.11297195\n",
      "  0.30870301 0.45819318 0.40929064 0.2740326  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.49517078 0.45143823 0.32406811 0.21238793 0.02590629\n",
      "  0.         0.         0.         0.         0.11752881 0.22805552\n",
      "  0.30870301 0.31637148 0.05622124 0.1826884  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13018574 0.38157279 0.32406811 0.27447056 0.20310532\n",
      "  0.057829   0.         0.03270973 0.21326326 0.26176872 0.26606477\n",
      "  0.29155284 0.0945478  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19526495 0.32406811 0.27447056 0.26113541\n",
      "  0.2812077  0.21627433 0.26545207 0.29856856 0.26924783 0.25233921\n",
      "  0.10535103 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04478554 0.25205298 0.27447056 0.26113541\n",
      "  0.28574331 0.31503544 0.31829087 0.29856856 0.25856339 0.16153933\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02957765 0.13832445 0.25595415\n",
      "  0.28574331 0.31503544 0.31829087 0.29856856 0.17415633 0.00316744\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09326265\n",
      "  0.28574331 0.31503544 0.31829087 0.29856856 0.26924783 0.11613938\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02178338 0.21139533\n",
      "  0.28687721 0.31628558 0.320807   0.29975335 0.27031627 0.18265558\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10564938 0.26113541\n",
      "  0.28574331 0.24377743 0.18367773 0.29264458 0.26924783 0.21749739\n",
      "  0.02817527 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.06301324 0.26575721 0.26113541\n",
      "  0.27213648 0.01500169 0.         0.09596847 0.25856339 0.26606477\n",
      "  0.12495122 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.21347344 0.27447056 0.26113541\n",
      "  0.14287165 0.         0.         0.         0.24146829 0.26606477\n",
      "  0.29645289 0.10182071 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09494534 0.30606433 0.27447056 0.26113541\n",
      "  0.12019361 0.         0.         0.         0.13035014 0.26606477\n",
      "  0.30870301 0.12000298 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09494534 0.30606433 0.27447056 0.26113541\n",
      "  0.12019361 0.         0.         0.         0.10043371 0.26606477\n",
      "  0.30870301 0.12000298 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23919313 0.27447056 0.26113541\n",
      "  0.14400555 0.         0.         0.04620704 0.20193587 0.26606477\n",
      "  0.29522788 0.10182071 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.13245641 0.27447056 0.26113541\n",
      "  0.2800738  0.2000225  0.20254873 0.29264458 0.26924783 0.26606477\n",
      "  0.20947704 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02957765 0.21456627 0.25595415\n",
      "  0.28574331 0.31503544 0.31829087 0.29856856 0.26390561 0.20693927\n",
      "  0.02695026 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07875512\n",
      "  0.14287165 0.31503544 0.31829087 0.14928428 0.08013328 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Checking the shape of the data sets\r\n",
    "print(x_train.shape)\r\n",
    "print(x_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# In order to make images 4D, we need to reshape them\r\n",
    "# Reshaping image in order to suit it for convolution operation\r\n",
    "input_shape = [28, 28, 1]\r\n",
    "x_train = x_train.reshape(len(x_train), input_shape[0], input_shape[1], input_shape[2])\r\n",
    "x_test = x_test.reshape(len(x_test), input_shape[0], input_shape[1], input_shape[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Checking the shape of the data sets after reshaping\r\n",
    "print(x_train.shape)\r\n",
    "print(x_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Creating a neural network\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "# First CNN layer\r\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=[28, 28, 1]))\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\r\n",
    "\r\n",
    "# Second CNN layer\r\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "# Third CNN layer\r\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "# Fully connected layers \r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dropout(0.5)) #Regularizing\r\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\r\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\r\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\r\n",
    "\r\n",
    "# Summarizing the performance of the model\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 100,554\n",
      "Trainable params: 100,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Compiling the model\r\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Training the model\r\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=15, validation_data=(x_test, y_test), validation_split=0.3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "4200/4200 [==============================] - 87s 20ms/step - loss: 0.3038 - accuracy: 0.9032 - val_loss: 0.0702 - val_accuracy: 0.9793\n",
      "Epoch 2/15\n",
      "4200/4200 [==============================] - 96s 23ms/step - loss: 0.1155 - accuracy: 0.9645 - val_loss: 0.0596 - val_accuracy: 0.9815\n",
      "Epoch 3/15\n",
      "4200/4200 [==============================] - 93s 22ms/step - loss: 0.0912 - accuracy: 0.9720 - val_loss: 0.0444 - val_accuracy: 0.9871\n",
      "Epoch 4/15\n",
      "4200/4200 [==============================] - 67s 16ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
      "Epoch 5/15\n",
      "4200/4200 [==============================] - 64s 15ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.0439 - val_accuracy: 0.9878\n",
      "Epoch 6/15\n",
      "4200/4200 [==============================] - 96s 23ms/step - loss: 0.0612 - accuracy: 0.9814 - val_loss: 0.0410 - val_accuracy: 0.9889\n",
      "Epoch 7/15\n",
      "4200/4200 [==============================] - 94s 22ms/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 0.0412 - val_accuracy: 0.9889\n",
      "Epoch 8/15\n",
      "4200/4200 [==============================] - 94s 22ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.0541 - val_accuracy: 0.9866\n",
      "Epoch 9/15\n",
      "4200/4200 [==============================] - 96s 23ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0345 - val_accuracy: 0.9910\n",
      "Epoch 10/15\n",
      "4200/4200 [==============================] - 112s 27ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.0400 - val_accuracy: 0.9893\n",
      "Epoch 11/15\n",
      "4200/4200 [==============================] - 112s 27ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.0389 - val_accuracy: 0.9897\n",
      "Epoch 12/15\n",
      "4200/4200 [==============================] - 76s 18ms/step - loss: 0.0450 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9906\n",
      "Epoch 13/15\n",
      "4200/4200 [==============================] - 62s 15ms/step - loss: 0.0398 - accuracy: 0.9887 - val_loss: 0.0436 - val_accuracy: 0.9905\n",
      "Epoch 14/15\n",
      "4200/4200 [==============================] - 59s 14ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.0410 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "4200/4200 [==============================] - 59s 14ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.0412 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Saving our trained model\r\n",
    "model.save('HAMARA_PYARA_MODEL.keras')\r\n",
    "print(\"[INFO] Model is saved successfully.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Model is saved successfully.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model using MNIST test samples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Ensuring if \"HAMARA_PAYARA_MODEL\" is worth training\r\n",
    "performance = model.evaluate(x_test, y_test, verbose=0)\r\n",
    "loss = performance[0]\r\n",
    "accuracy = performance[1]\r\n",
    "print(\"[LOSS]: \",loss)\r\n",
    "print(\"[ACCURACY]: \",accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOSS]:  0.0306325051933527\n",
      "[ACCURACY]:  0.9930999875068665\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Preparing to predict \"HAMARA_PAYARA_MODEL\"\r\n",
    "prediction = model.predict(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# TRIAL NO. - 1\r\n",
    "# Predicting \"HAMARA_PAYARA_MODEL\" taking random index inputs\r\n",
    "predictionMax = np.argmax(prediction[127])\r\n",
    "\r\n",
    "# Printing model's O/P\r\n",
    "print(\"[O/P] HAMARA_PAYARA_MODEL says: It's a\",predictionMax)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[O/P] HAMARA_PAYARA_MODEL says: It's a 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Checking whether the O/P is correct or not by plotting the image at index 127\r\n",
    "plt.imshow(x_test[127])\r\n",
    "print(\"It's a 5\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's a 5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# TRIAL NO. - 2\r\n",
    "# Predicting \"HAMARA_PAYARA_MODEL\" taking random index inputs\r\n",
    "predictionMax2 = np.argmax(prediction[0])\r\n",
    "\r\n",
    "# Printing model's O/P\r\n",
    "print(\"[O/P] HAMARA_PAYARA_MODEL says: It's a\",predictionMax2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[O/P] HAMARA_PAYARA_MODEL says: It's a 7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Checking whether the O/P is correct or not by plotting the image at index 0\r\n",
    "plt.imshow(x_test[0])\r\n",
    "print(\"It's 7(MY FAV DIGIT)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's 7(MY FAV DIGIT)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74b0a38879f80463ab999397bfa9db9d3cd5fd53c7393138d0c98665aeeeaeaa"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}